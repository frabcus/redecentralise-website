---
layout: article
categories: blog
summary: "After the Capitol riot, the question isn't about how the social media monopolists should wield their power - the question is whether they should have such power in the first place."
title: "Centralisation is a danger to democracy"
date: 2021-01-18
author: "rysiek"
footer: |
  <i>An version of this post appeared [on vsquare.org](https://vsquare.org/centralisation-is-a-danger-to-democracy/)</i>
  <i>This post is licensed under the [Creative Commons &mdash; By Attribution 4.0](https://creativecommons.org/licenses/by/4.0/) license.</i>
---

# Centralisation is a danger to democracy

After the [violent events](https://www.theguardian.com/us-news/2021/jan/06/trump-mob-capitol-clash-police-washington) at the US Capitol social media [monopolists](https://mashable.com/article/house-antitrust-report-facebook-privacy-misinformation/) are finally waking up to the reality that centralisation is dangerous; with power over daily communication of [hundreds of millions of users](https://chrissniderdesign.com/blog/resources/social-media-statistics/) comes responsibility perhaps too big even for Big Tech.

For years Facebook and Twitter were [unwilling to enforce their own rules](https://www.newyorker.com/magazine/2020/10/19/why-facebook-cant-fix-itself) against those inciting violence, in fear of upsetting a substantial part of their userbase. Now, by [banning the accounts of Donald Trump](https://www.theguardian.com/us-news/2021/jan/08/donald-trump-twitter-ban-suspended) and peddlers of [QAnon conspiracy theory](https://www.cnbc.com/2021/01/08/twitter-bans-michael-flynn-sidney-powell-and-other-qanon-accounts.html) they are hoping to put the genie back in the bottle, and go back to business as usual.

Not only is this too little too late, but needs to be understood as an [admission of complicity](https://arstechnica.com/tech-policy/2021/01/despite-facebooks-attempts-pro-trump-events-groups-still-flourish/).

After all, nothing really changed in President Trump's rhetoric, or in the [wild substance of QAnon conspiracy theories](https://www.bellingcat.com/news/americas/2021/01/07/the-making-of-qanon-a-crowdsourced-conspiracy/). Social media monopolists [were warned for years](https://www.businessinsider.com/facebook-ignored-warnings-violent-anti-muslim-militia-hate-groups-2015-2020-9) that promoting this kind of content will lead to bloodshed (and [it has in the past already](https://www.bbc.com/news/world-asia-46105934)).

Could it be that [after the electoral shake-up](https://types.pl/@hazel/105522730408015610) what used to be an asset became a [liability](https://www.stophateforprofit.org/)?

## A "difficult position"

I have participated in many a public forum on Internet governance, and whenever anyone pointed out that social platforms like Facebook need to do more as far as content moderation is concerned, Facebook would complain that it's difficult in their huge network, since regulation and cultures are so different across the world.

They're not wrong! But while their goal was to stifle further regulation, they were in fact making a very good argument for decentralisation.

After all the very reason they are in this "difficult position" is their business decision to insist on providing [centrally-controlled](https://blog.joinmastodon.org/2018/03/twitter-is-not-a-public-utility/) global social media platforms, [trying to push the round peg of a myriad of cultures](https://thenextweb.com/socialmedia/2019/02/26/facebooks-global-content-moderation-fails-to-account-for-regional-sensibilities/) into [a square hole of a single moderation policy](https://www.vice.com/en/article/xwk9zd/how-facebook-content-moderation-works).

Social media behemoths argued for years that democratically elected governments [should not regulate them](https://www.theverge.com/2019/10/1/20756701/mark-zuckerberg-facebook-leak-audio-ftc-antitrust-elizabeth-warren-tiktok-comments) according to the will of the people, because it is incompatible with their business models!

Meanwhile they were [ignoring calls](https://techcrunch.com/2018/05/29/facebooks-white-nationalism-white-supremacy-policy-motherboard/) to stifle the spread of violent white supremacy, making money hand over fist by [outright ](https://www.technologyreview.com/2020/01/29/276000/a-study-of-youtube-comments-shows-how-its-turning-people-onto-the-alt-right/)*[promoting](https://www.technologyreview.com/2020/01/29/276000/a-study-of-youtube-comments-shows-how-its-turning-people-onto-the-alt-right/)* [extremist content](https://www.politico.com/news/2020/09/26/facebook-conservatives-2020-421146) (something [their own research confirms](https://www.wsj.com/articles/facebook-knows-it-encourages-division-top-executives-nixed-solutions-11590507499)).

[Damage done to the social fabric itself](https://medium.com/swlh/do-virtual-social-networks-destroy-the-social-fabric-b1e96de514db) is, unsurprisingly, just an externality.

## Damned if you do, damned if you don't

Of course, major social media platforms banning anyone immediately raise concerns about censorship (and those abusing those social networks to spread a message of hate and division know how to use this argument well). Do we want to live in a world where a handful of corporate execs control the *de-facto* online public space for political and social debate?

[Obviously](https://www.eff.org/deeplinks/2020/12/decade-after-arab-spring-platforms-have-turned-their-backs-critical-voices-middle) [we](https://www.wired.com/story/mark-zuckerberg-is-an-arbiter-of-truth-whether-he-likes-it-or-not/) [don't](https://gizmodo.com/twitter-doesnt-like-piracy-even-when-its-in-the-public-1846022460). This is too much power, and power corrupts. But the question isn't really about how these platforms should wield their power &mdash; **the question is whether these platforms should have such power in the first place**.

And the answer is a resounding "*no*".

## Universe of alternatives

There is another way. [The Fediverse](https://medium.com/@VirtualAdept/a-friendly-introduction-to-the-fediverse-5b4ef3f8ed0e) is a *decentralised* social network.

Imagine if Twitter and Facebook worked the way e-mail providers do: you can have an account on any *instance* (as servers are called on the Fediverse), and different instances talk to each other â€” If you have an account on, say, [`mastodon.social`](https://mastodon.social/), you can still talk to users over at `pleroma.soykaf.com` or almost any other compatible instance.

Individual instances are run by different people or communities, using [different software](https://fediverse.party/), and each has their own rules.

These rules are enforced using [moderation tools](https://docs.joinmastodon.org/admin/moderation/), some of which are simply not possible in a centralised network. Not only are moderators able to block or silence particular accounts, but also block (or, "*defederate from*") whole instances which cater to abusive users &mdash; which is inconceivable if the whole network is a single "instance".

Additionally, each user has the ability to block or silence threads, abusive users, or whole instances, too. All this means that the response to abusive users can be fine-tuned. Because Fediverse communities run their own instances, they care about keeping any abuse or discrimination at bay, and they have the agency to do just that.

## Local rules instead of global censorship

White supremacy and alt-right trolling were a problem also on the Fediverse. Services like [Gab](https://en.wikipedia.org/wiki/Gab_(social_network)) tried to become part of it, and individual bad actors were setting up accounts on other instances.

They were, however, [decisively repudiated](https://todon.nl/@isolategab) by a combination of better moderation tools, [communities ](https://nerdica.net/tos)[being](https://mastodon.social/about/more) [clear](https://eldritch.cafe/about/more#rules) about what is and what is not acceptable on their instances, and [moderators and admins being unapologetic](https://mastodon.technology/@ashfurrow/105523289076755882) about blocking abusive users or defederating from instances that are problematic.

[This talk](https://conf.tube/videos/watch/d8c8ed69-79f0-4987-bafe-84c01f38f966) by technology writer and researcher [Derek Caelin](https://mastodon.technology/@Argus) provides pretty good overview of this (along with quite some data), I can only recommend watching it in full.

Now, alt-right trolls and white supremacists are all but limited to a corner of the Fediverse almost nobody else talks to. While it does not prevent a dedicated group from talking hatefully among themselves on their own instance (like Gab), it does isolate them, makes radicalising new users harder, and protects others from potential abuse. They are also, of course, welcome to create accounts on other instances, provided that they behave themselves.

All that despite there not being a central authority to enforce the rules. Turns out not many people like talking to or platforming fascists.

## Way forward

Instead of trying to come up with a single centrally-mandated set of rules &mdash; forcing it on everyone and acting surprised [when that inevitably fails](https://www.businessinsider.com/facebook-failing-to-enforce-its-own-content-policies-report-2020-10) &mdash; it is time to recognise that [different communities have different sensibilities](https://www.article19.org/resources/the-global-impact-of-content-moderation/), and members of these communities better understand the context and can best enforce their rules.

On an individual level, you can [join the Fediverse](https://fediverse.party/en/portal/servers). Collectively, we should break down the walls of mainstream social media, [regulate them](https://www.youtube.com/watch?v=1Xumfp8vKGE), and make monetising toxic engagement spilling into public discourse as onerous as dumping toxic waste into a river.

In the end even the monopolists are slowly recognising [moderation in a global centralised network is impossible](https://twitter.com/jack/status/1204766078468911106) and that [there is a need for more regulation](https://about.fb.com/news/2020/02/big-tech-needs-more-regulation/). Perhaps everyone else should too.
